{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "id": "pllUxS7Kzz_R"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "id": "NZfnrVb70jR1"
   },
   "outputs": [],
   "source": [
    "file = tf.keras.utils.get_file(\n",
    "    'shakespeare.txt',\n",
    "    'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lez-9Wvb046h",
    "outputId": "441e4f24-ea02-4b2b-e809-a9735fea48dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "RkT_7qBz0-GG",
    "outputId": "4610465e-0387-4aab-bd85-90ec047d6a55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Archit\\\\.keras\\\\datasets\\\\shakespeare.txt'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "id": "TbKpKJeJ1ACu"
   },
   "outputs": [],
   "source": [
    "text = open(file,'rb').read().decode(encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FR6m-yhX1MN5",
    "outputId": "bc9c5173-aa23-4405-d148-1342765c6164"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "peMhyr0g1Q0S",
    "outputId": "d019ea63-1e96-4cd7-e612-fc36f79984d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us\n"
     ]
    }
   ],
   "source": [
    "print(text[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Bo-ftud1Tv1",
    "outputId": "4473f252-5573-4147-8a44-04f6c58cd926"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8PTUKHWY1fQr",
    "outputId": "18a0e941-5baa-4881-a8b3-429ade96fd28"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "ucqS8nWB1nO_"
   },
   "outputs": [],
   "source": [
    "vocab = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IagjA1vB1rrX",
    "outputId": "b4017f3b-3924-4b0f-e388-f985600af3f4",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '$',\n",
       " '&',\n",
       " \"'\",\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '3',\n",
       " ':',\n",
       " ';',\n",
       " '?',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting text to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "UhX6cGfz1tKK"
   },
   "outputs": [],
   "source": [
    " c2i = {a:i for i,a in enumerate(vocab)} # char to index mattping through dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '$': 3,\n",
       " '&': 4,\n",
       " \"'\": 5,\n",
       " ',': 6,\n",
       " '-': 7,\n",
       " '.': 8,\n",
       " '3': 9,\n",
       " ':': 10,\n",
       " ';': 11,\n",
       " '?': 12,\n",
       " 'A': 13,\n",
       " 'B': 14,\n",
       " 'C': 15,\n",
       " 'D': 16,\n",
       " 'E': 17,\n",
       " 'F': 18,\n",
       " 'G': 19,\n",
       " 'H': 20,\n",
       " 'I': 21,\n",
       " 'J': 22,\n",
       " 'K': 23,\n",
       " 'L': 24,\n",
       " 'M': 25,\n",
       " 'N': 26,\n",
       " 'O': 27,\n",
       " 'P': 28,\n",
       " 'Q': 29,\n",
       " 'R': 30,\n",
       " 'S': 31,\n",
       " 'T': 32,\n",
       " 'U': 33,\n",
       " 'V': 34,\n",
       " 'W': 35,\n",
       " 'X': 36,\n",
       " 'Y': 37,\n",
       " 'Z': 38,\n",
       " 'a': 39,\n",
       " 'b': 40,\n",
       " 'c': 41,\n",
       " 'd': 42,\n",
       " 'e': 43,\n",
       " 'f': 44,\n",
       " 'g': 45,\n",
       " 'h': 46,\n",
       " 'i': 47,\n",
       " 'j': 48,\n",
       " 'k': 49,\n",
       " 'l': 50,\n",
       " 'm': 51,\n",
       " 'n': 52,\n",
       " 'o': 53,\n",
       " 'p': 54,\n",
       " 'q': 55,\n",
       " 'r': 56,\n",
       " 's': 57,\n",
       " 't': 58,\n",
       " 'u': 59,\n",
       " 'v': 60,\n",
       " 'w': 61,\n",
       " 'x': 62,\n",
       " 'y': 63,\n",
       " 'z': 64}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2i['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "i2c = np.array(vocab) # idex to char mapping thru np array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.str_('x')"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2c[62]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_as_seq_of_ints = np.array([c2i[a] for a in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18, 47, 56, 57, 58,  1, 15, 47, 58, 47])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_as_seq_of_ints[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['F', 'i', 'r', 's', 't', ' ', 'C', 'i', 't', 'i'], dtype='<U1')"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2c[text_as_seq_of_ints[:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper fxns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 120 #len of ip nd coresp tgt\n",
    "examples_per_epoch = len(text)//(seq_length + 1) # +1 for the shift "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_seq_of_ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F 18\n",
      "i 47\n",
      "r 56\n",
      "s 57\n",
      "t 58\n",
      "  1\n",
      "C 15\n",
      "i 47\n",
      "t 58\n",
      "i 47\n",
      "z 64\n",
      "e 43\n",
      "n 52\n",
      ": 10\n",
      "\n",
      " 0\n",
      "B 14\n",
      "e 43\n",
      "f 44\n",
      "o 53\n",
      "r 56\n"
     ]
    }
   ],
   "source": [
    "for i in char_dataset.take(20):\n",
    "    print(i2c[i.numpy()],i.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = char_dataset.batch(seq_length + 1, drop_remainder = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F' 'i' 'r' 's' 't' ' ' 'C' 'i' 't' 'i' 'z' 'e' 'n' ':' '\\n' 'B' 'e' 'f'\n",
      " 'o' 'r' 'e' ' ' 'w' 'e' ' ' 'p' 'r' 'o' 'c' 'e' 'e' 'd' ' ' 'a' 'n' 'y'\n",
      " ' ' 'f' 'u' 'r' 't' 'h' 'e' 'r' ',' ' ' 'h' 'e' 'a' 'r' ' ' 'm' 'e' ' '\n",
      " 's' 'p' 'e' 'a' 'k' '.' '\\n' '\\n' 'A' 'l' 'l' ':' '\\n' 'S' 'p' 'e' 'a'\n",
      " 'k' ',' ' ' 's' 'p' 'e' 'a' 'k' '.' '\\n' '\\n' 'F' 'i' 'r' 's' 't' ' ' 'C'\n",
      " 'i' 't' 'i' 'z' 'e' 'n' ':' '\\n' 'Y' 'o' 'u' ' ' 'a' 'r' 'e' ' ' 'a' 'l'\n",
      " 'l' ' ' 'r' 'e' 's' 'o' 'l' 'v' 'e' 'd' ' ' 'r' 'a' 't']\n",
      "['h' 'e' 'r' ' ' 't' 'o' ' ' 'd' 'i' 'e' ' ' 't' 'h' 'a' 'n' ' ' 't' 'o'\n",
      " ' ' 'f' 'a' 'm' 'i' 's' 'h' '?' '\\n' '\\n' 'A' 'l' 'l' ':' '\\n' 'R' 'e'\n",
      " 's' 'o' 'l' 'v' 'e' 'd' '.' ' ' 'r' 'e' 's' 'o' 'l' 'v' 'e' 'd' '.' '\\n'\n",
      " '\\n' 'F' 'i' 'r' 's' 't' ' ' 'C' 'i' 't' 'i' 'z' 'e' 'n' ':' '\\n' 'F' 'i'\n",
      " 'r' 's' 't' ',' ' ' 'y' 'o' 'u' ' ' 'k' 'n' 'o' 'w' ' ' 'C' 'a' 'i' 'u'\n",
      " 's' ' ' 'M' 'a' 'r' 'c' 'i' 'u' 's' ' ' 'i' 's' ' ' 'c' 'h' 'i' 'e' 'f'\n",
      " ' ' 'e' 'n' 'e' 'm' 'y' ' ' 't' 'o' ' ' 't' 'h' 'e' ' ']\n"
     ]
    }
   ],
   "source": [
    "for i in seq.take(2):\n",
    "    print(i2c[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (50, 120)\n",
      "Target shape: (50, 120)\n",
      "Dtype: <dtype: 'int64'>\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset.take(1):\n",
    "    print(\"Input shape:\", input_example.shape)\n",
    "    print(\"Target shape:\", target_example.shape)\n",
    "    print(\"Dtype:\", input_example.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_make_input_target_pairs(s):\n",
    "    input_text = s[:-1] # all but last\n",
    "    target_text = s[1:] # all but 1st\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = seq.map(f_make_input_target_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F' 'i' 'r' 's' 't' ' ' 'C' 'i' 't' 'i' 'z' 'e' 'n' ':' '\\n' 'B' 'e' 'f'\n",
      " 'o' 'r' 'e' ' ' 'w' 'e' ' ' 'p' 'r' 'o' 'c' 'e' 'e' 'd' ' ' 'a' 'n' 'y'\n",
      " ' ' 'f' 'u' 'r' 't' 'h' 'e' 'r' ',' ' ' 'h' 'e' 'a' 'r' ' ' 'm' 'e' ' '\n",
      " 's' 'p' 'e' 'a' 'k' '.' '\\n' '\\n' 'A' 'l' 'l' ':' '\\n' 'S' 'p' 'e' 'a'\n",
      " 'k' ',' ' ' 's' 'p' 'e' 'a' 'k' '.' '\\n' '\\n' 'F' 'i' 'r' 's' 't' ' ' 'C'\n",
      " 'i' 't' 'i' 'z' 'e' 'n' ':' '\\n' 'Y' 'o' 'u' ' ' 'a' 'r' 'e' ' ' 'a' 'l'\n",
      " 'l' ' ' 'r' 'e' 's' 'o' 'l' 'v' 'e' 'd' ' ' 'r' 'a']\n",
      "['i' 'r' 's' 't' ' ' 'C' 'i' 't' 'i' 'z' 'e' 'n' ':' '\\n' 'B' 'e' 'f' 'o'\n",
      " 'r' 'e' ' ' 'w' 'e' ' ' 'p' 'r' 'o' 'c' 'e' 'e' 'd' ' ' 'a' 'n' 'y' ' '\n",
      " 'f' 'u' 'r' 't' 'h' 'e' 'r' ',' ' ' 'h' 'e' 'a' 'r' ' ' 'm' 'e' ' ' 's'\n",
      " 'p' 'e' 'a' 'k' '.' '\\n' '\\n' 'A' 'l' 'l' ':' '\\n' 'S' 'p' 'e' 'a' 'k'\n",
      " ',' ' ' 's' 'p' 'e' 'a' 'k' '.' '\\n' '\\n' 'F' 'i' 'r' 's' 't' ' ' 'C' 'i'\n",
      " 't' 'i' 'z' 'e' 'n' ':' '\\n' 'Y' 'o' 'u' ' ' 'a' 'r' 'e' ' ' 'a' 'l' 'l'\n",
      " ' ' 'r' 'e' 's' 'o' 'l' 'v' 'e' 'd' ' ' 'r' 'a' 't']\n"
     ]
    }
   ],
   "source": [
    "for X,y in dataset.take(1):\n",
    "    print(i2c[X.numpy()])\n",
    "    print(i2c[y.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 50 # Batch Size\n",
    "dataset = dataset.shuffle(1000).batch(BS,drop_remainder = True) # unbiases dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "VS = len(vocab) # Vocab size\n",
    "ED = 120 # embedding Dimention each char will be a 120 dim dense vector\n",
    "NU = 1024 # No of Units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# defining model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_make_model(VS, ED, NU, BS):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(None,), batch_size=BS),  # <-- define batch input here\n",
    "        tf.keras.layers.Embedding(VS, ED),\n",
    "        tf.keras.layers.GRU(NU, return_sequences=True, stateful=True),\n",
    "        tf.keras.layers.Dense(VS)\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (50, 120)\n",
      "Target shape: (50, 120)\n",
      "Input dtype: <dtype: 'int64'>\n"
     ]
    }
   ],
   "source": [
    "for x, y in dataset.take(1):\n",
    "    print(\"Input shape:\", x.shape)  \n",
    "    print(\"Target shape:\", y.shape)  \n",
    "    print(\"Input dtype:\", x.dtype)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building/ Compiling model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = f_make_model(VS,ED,NU,BS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_loss(y,y_hat):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(y,y_hat,from_logits = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = f_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run, Training nd Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './tr_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"chpt_{epoch}.weights.h5\")\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = checkpoint_prefix,\n",
    "    save_weights_only = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 1s/step - loss: 3.1361\n",
      "Epoch 2/15\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 1s/step - loss: 2.0118\n",
      "Epoch 3/15\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 1s/step - loss: 1.7340\n",
      "Epoch 4/15\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 1s/step - loss: 1.5643\n",
      "Epoch 5/15\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 1s/step - loss: 1.4630\n",
      "Epoch 6/15\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 1s/step - loss: 1.3964\n",
      "Epoch 7/15\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 1s/step - loss: 1.3492\n",
      "Epoch 8/15\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 1s/step - loss: 1.3053\n",
      "Epoch 9/15\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 1s/step - loss: 1.2684\n",
      "Epoch 10/15\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 1s/step - loss: 1.2362\n",
      "Epoch 11/15\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 1s/step - loss: 1.2034\n",
      "Epoch 12/15\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 1s/step - loss: 1.1693\n",
      "Epoch 13/15\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 1s/step - loss: 1.1392\n",
      "Epoch 14/15\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 1s/step - loss: 1.1036\n",
      "Epoch 15/15\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 1s/step - loss: 1.0694\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs = 15,\n",
    "                   callbacks = [checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual weight loading due to Keras 3 only supporting `.weights.h5` format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = f_make_model(VS, ED, NU, 1)  # Create a new model with batch_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from: ./tr_checkpoints\\chpt_15.weights.h5\n"
     ]
    }
   ],
   "source": [
    "import glob \n",
    "import os\n",
    "\n",
    "checkpoint_dir = './tr_checkpoints'\n",
    "checkpoints = glob.glob(os.path.join(checkpoint_dir, '*.weights.h5'))\n",
    "latest_checkpoint = max(checkpoints, key=os.path.getctime)\n",
    "\n",
    "print(f\"Loading weights from: {latest_checkpoint}\")\n",
    "model.load_weights(latest_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./tr_checkpoints'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build(tf.TensorShape([1, None]))  # Build it with shape (1, variable length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuction to generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_write_now(model, ss):\n",
    "    N = 2000  # number of characters to generate\n",
    "    ie = [c2i[a] for a in ss]  # input evaluation\n",
    "    ie = tf.expand_dims(ie, 0)\n",
    "    g_text = []\n",
    "    \n",
    "    # Reset GRU states (GRU is at index 2 in the Sequential model)\n",
    "    model.layers[1].reset_states()\n",
    "\n",
    "    for i in range(N):\n",
    "        p = model(ie)\n",
    "        p = tf.squeeze(p, 0)\n",
    "        p_id = tf.random.categorical(p, num_samples=1)[-1, 0].numpy()\n",
    "        ie = tf.expand_dims([p_id], 0)\n",
    "        g_text.append(i2c[p_id])\n",
    "        \n",
    "    return ss + ''.join(g_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHINNU: Hello there.\n",
      "ARCHIT: what have we got here in Grood:\n",
      "And if thou beast will set upon his eye.\n",
      "\n",
      "PROSPERO:\n",
      "So for my master, widow Dido,\n",
      "And there's married o' the better husband's rock.\n",
      "\n",
      "CAMILLO:\n",
      "I think but a King of Faulinare 's:\n",
      "Was! Alack, for some VINCENTIO:\n",
      "'Tis a very son.\n",
      "\n",
      "LUCENTIO:\n",
      "What?\n",
      "Es he mischief?\n",
      "\n",
      "ANGOLIO:\n",
      "My good lord, then he comes no went?\n",
      "\n",
      "LUCENTIO:\n",
      "The unfiedy garter of mine own defention.\n",
      "Knowing that have comfort in the which he sleep?\n",
      "\n",
      "Boatswain:\n",
      "Good star, for what is dear Signior Baptista.\n",
      "\n",
      "BIANCA:\n",
      "Plantagenet and\n",
      "The queen in Lord Hastings: 'tis entioliver,\n",
      "And hang thee in the worst of the meat, thou\n",
      "she that ruled.\n",
      "\n",
      "Callings ad Aful, thou didst know\n",
      "If the people's greatness, ha?\n",
      "\n",
      "CURTIS:\n",
      "The nunsing daughter in the frust.\n",
      "\n",
      "LUCENTIO:\n",
      "Tell me, give thee shade, thou rettly help me.\n",
      "\n",
      "BRUTUS:\n",
      "He'll hear his large:\n",
      "I jest Benvole, and joor. A boxt a lipe\n",
      "Go assent in call him your bath; and wild go slay thee forth\n",
      "And married on, she shall not gaze you'll Be:\n",
      "What, I am paunting for loughs that I am out of mohem,\n",
      "Whil thou disstructs o' the street?\n",
      "\n",
      "ESCALUS:\n",
      "Do not growes without:\n",
      "Only no, no, there's my father's allies;\n",
      "Foot thou lost your housesoe, look forth him that he speditation\n",
      "to a bod hang indeed the ground,--\n",
      "\n",
      "SEBASTIAN:\n",
      "Petruchio's satisfacts, thence a forwardness he swared.\n",
      "Widow Dido! if the place all this giddy wouldst do,\n",
      "Or. of all two mignible school-masters! ntweathablits are well false.\n",
      "\n",
      "Post:\n",
      "A homeford, my lord,\n",
      "Here lies you, even show'd at hot, then being all the stranger:\n",
      "To whom they set his end in drums of like Bohemia's war,\n",
      "And kneel you of something strange. All men, yet, Plunt, and not\n",
      "Upon his hands; who, as I have stay'd and showed\n",
      "To stay dinner:\n",
      "Cursed him something; I vill you forget\n",
      "That I intend him plainly alter'd with one day,\n",
      "too crowns me poziling as well;\n",
      "Her wafer we should entreat these lord:\n",
      "I am a thing, the thing shows there is no right.\n",
      "\n",
      "BAPTISTA:\n",
      "Sooth some of you bound, put your peds,\n",
      "And thou should be done.\n",
      "Justle, no less: Kate, com\n"
     ]
    }
   ],
   "source": [
    "ss = u\"\"\"CHINNU: Hello there.\n",
    "ARCHIT: what have we got here\"\"\"\n",
    "print(f_write_now(model,ss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
